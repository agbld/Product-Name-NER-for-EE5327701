{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\clw20\\anaconda3\\envs\\cl\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertPreTrainedModel, BertModel\n",
    "from transformers import BertTokenizerFast\n",
    "from src import config\n",
    "from data_process import dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from seqeval.metrics import f1_score\n",
    "from seqeval.metrics import precision_score\n",
    "from seqeval.metrics import recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\"clw8998/Product-Name-NER-model\")\n",
    "processed_train_data = [\n",
    "        {\n",
    "            'context': '【享夢城堡】超柔暖暖毯被150x195cm-角落小夥伴 壽司貓-膚橘',\n",
    "            'question': '品牌',\n",
    "            'answer': [\n",
    "                'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', \n",
    "                'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', \n",
    "                'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'\n",
    "            ]\n",
    "        }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': [[101, 523, 775, 1918, 1814, 1836, 524, 6631, 3382, 3265, 3265, 3691, 6158, 8269, 8206, 8818, 8157, 8341, 118, 6235, 5862, 2207, 1919, 845, 1904, 1385, 6506, 118, 5604, 3580, 102, 1501, 4277, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'offset_mapping': [[(0, 0), (0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 9), (9, 10), (10, 11), (11, 12), (12, 15), (15, 16), (16, 18), (18, 19), (19, 21), (21, 22), (22, 23), (23, 24), (24, 25), (25, 26), (26, 27), (28, 29), (29, 30), (30, 31), (31, 32), (32, 33), (33, 34), (0, 0), (0, 1), (1, 2), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0)]], 'gt': [0, 0, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100], 'p_name': '【享夢城堡】超柔暖暖毯被150x195cm-角落小夥伴 壽司貓-膚橘'},\n",
       " 0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokeniz輸入字串，然後改成格式: [BOS] 商品名稱 [SEP] 屬性 [SEP]\n",
    "train_dataset = dataset.BERTDataset_preprocess(processed_train_data, [], tokenizer)\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset = train_dataset,\n",
    "                            batch_size = 1,\n",
    "                            shuffle = True,\n",
    "                            num_workers = 2,\n",
    "                            collate_fn = dataset.BERTDataset_preprocess.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs:\n",
      " tensor([[ 101,  523,  775, 1918, 1814, 1836,  524, 6631, 3382, 3265, 3265, 3691,\n",
      "         6158, 8269, 8206, 8818, 8157, 8341,  118, 6235, 5862, 2207, 1919,  845,\n",
      "         1904, 1385, 6506,  118, 5604, 3580,  102, 1501, 4277,  102,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0]])\n",
      "Attention Mask:\n",
      " tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "Token Type IDs:\n",
      " tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "Index:\n",
      " [0]\n",
      "Batch GT (Ground Truths):\n",
      " tensor([[   0,    0,    2,    1,    1,    1,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100]])\n",
      "Offset Mapping:\n",
      " [[(0, 0), (0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 9), (9, 10), (10, 11), (11, 12), (12, 15), (15, 16), (16, 18), (18, 19), (19, 21), (21, 22), (22, 23), (23, 24), (24, 25), (25, 26), (26, 27), (28, 29), (29, 30), (30, 31), (31, 32), (32, 33), (33, 34), (0, 0), (0, 1), (1, 2), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0)]]\n",
      "P Names:\n",
      " ['【享夢城堡】超柔暖暖毯被150x195cm-角落小夥伴 壽司貓-膚橘']\n"
     ]
    }
   ],
   "source": [
    "for batch_data, index, batch_gt, offset_mapping, p_names in train_loader:\n",
    "    # 提取所需的資料\n",
    "    input_ids = batch_data[0]\n",
    "    attention_mask = batch_data[2]\n",
    "    token_type_ids = batch_data[1]\n",
    "    index = index\n",
    "    batch_gt = batch_gt\n",
    "    offset_mapping = offset_mapping\n",
    "    p_names = p_names\n",
    "\n",
    "    print(\"Input IDs:\\n\", input_ids) # 輸入到模型的資料，token ids\n",
    "    print(\"Attention Mask:\\n\", attention_mask) # 輸入到模型的資料，atteention，0 代表該token不被關注\n",
    "    print(\"Token Type IDs:\\n\", token_type_ids) # 輸入到模型的資料，token type，0 代標商品名稱的token，1 代標問題的token\n",
    "    print(\"Index:\\n\", index) # 用不到\n",
    "    print(\"Batch GT (Ground Truths):\\n\", batch_gt) # 正確答案，2代表實體的B，1代表實體的I，0代表O，-100代表忽略\n",
    "    print(\"Offset Mapping:\\n\", offset_mapping) # 每個token對應到輸入字串的區間\n",
    "    print(\"P Names:\\n\", p_names) # 原始輸入之商品名稱\n",
    "    break\n",
    "\n",
    "# [BOS] '【享夢城堡】超柔暖暖毯被150x195cm-角落小夥伴 壽司貓-膚橘' [SEP] '品牌' [SEP]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Contextual_BERT(BertPreTrainedModel):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "        self.QA = Question_Answering()\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids,\n",
    "        gt = None,\n",
    "        attention_mask = None,\n",
    "        token_type_ids = None,\n",
    "        position_ids = None,\n",
    "        head_mask = None,\n",
    "        inputs_embeds = None,\n",
    "        output_attentions = None,\n",
    "        output_hidden_states = None,\n",
    "        return_dict = None,\n",
    "    ):\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        \n",
    "        hidden_states = outputs[0]    # 0 代表最後一層的輸出，長度與輸入相同(bs, max_length, 768), 1 代表第0個token的向量，(bs, 768)\n",
    "        return self.QA(hidden_states)\n",
    "            \n",
    "class Question_Answering(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.BIO_classifier = torch.nn.Linear(config.hidden, 3)\n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "        \n",
    "\n",
    "    def forward(self, batch_hidden_states):\n",
    "        \n",
    "        batch_hidden_states = self.dropout(batch_hidden_states)\n",
    "        batch_logits = self.BIO_classifier(batch_hidden_states).squeeze() # dim = (bs, max_query_len, 3)\n",
    "        return batch_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Contextual_BERT.from_pretrained(\"clw8998/Product-Name-NER-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Contextual_BERT(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-2): 3 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (QA): Question_Answering(\n",
       "    (BIO_classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8.1059, -4.0888, -4.5058],\n",
       "        [ 8.0974, -3.8082, -4.7128],\n",
       "        [-2.9853, -2.1178,  5.8071],\n",
       "        [-3.4841,  6.4687, -3.3589],\n",
       "        [-3.6310,  6.3099, -2.9481],\n",
       "        [-3.3073,  6.4135, -3.4099],\n",
       "        [ 8.0723, -3.8192, -4.7608],\n",
       "        [ 7.8756, -4.2779, -4.0285],\n",
       "        [ 7.9492, -3.8682, -4.7294],\n",
       "        [ 7.9941, -4.2765, -4.3242],\n",
       "        [ 8.0210, -3.8359, -4.8442],\n",
       "        [ 7.4887, -3.4424, -4.8452],\n",
       "        [ 7.9901, -3.5014, -5.2639],\n",
       "        [ 7.9308, -3.9771, -4.4201],\n",
       "        [ 8.0414, -3.7620, -4.8761],\n",
       "        [ 8.0760, -3.8390, -4.7921],\n",
       "        [ 8.0908, -3.8313, -4.8225],\n",
       "        [ 8.1038, -3.9345, -4.7146],\n",
       "        [ 8.1054, -3.8269, -4.7686],\n",
       "        [ 7.4536, -4.3248, -3.5178],\n",
       "        [ 7.4464, -3.6202, -4.4964],\n",
       "        [ 7.5143, -3.7000, -4.4047],\n",
       "        [ 7.4665, -3.6719, -4.3938],\n",
       "        [ 7.5233, -3.6240, -4.4983],\n",
       "        [ 7.4242, -4.1915, -3.6446],\n",
       "        [ 7.4969, -3.4840, -4.6253],\n",
       "        [ 7.2133, -3.4239, -4.4558],\n",
       "        [ 7.8171, -3.5470, -4.9293],\n",
       "        [ 7.9682, -4.1772, -4.2412],\n",
       "        [ 8.0395, -4.0654, -4.5008],\n",
       "        [ 8.1076, -4.0868, -4.5047],\n",
       "        [-2.1727,  3.4013, -0.9172],\n",
       "        [-1.2744,  4.6341, -3.7638],\n",
       "        [ 8.1086, -4.0849, -4.5036],\n",
       "        [ 4.5657, -2.6544, -2.6164],\n",
       "        [ 3.9032, -1.5493, -3.0086],\n",
       "        [ 3.6083, -1.6102, -2.5903],\n",
       "        [ 4.7318, -2.3861, -2.9747],\n",
       "        [ 4.1391, -2.1233, -2.7016],\n",
       "        [ 3.5962, -1.6128, -2.5681],\n",
       "        [ 4.5768, -1.9690, -3.3944],\n",
       "        [ 5.0071, -2.0499, -3.7733],\n",
       "        [ 5.8637, -2.5256, -4.1759],\n",
       "        [ 3.9669, -2.1439, -2.6163],\n",
       "        [ 4.0587, -1.8611, -2.8255],\n",
       "        [ 2.7902, -2.0091, -1.2847],\n",
       "        [ 2.4696, -2.4855, -0.4171],\n",
       "        [ 1.4348, -1.2099, -0.7059],\n",
       "        [ 2.7705, -2.0898, -1.2948],\n",
       "        [ 1.1202, -0.7591, -0.4955],\n",
       "        [ 2.5033, -1.0777, -1.9356],\n",
       "        [ 0.9982,  0.0989, -1.1482],\n",
       "        [ 3.2784, -1.6824, -2.0488],\n",
       "        [ 3.3298, -1.6870, -2.2398],\n",
       "        [ 4.1990, -2.0437, -2.7799],\n",
       "        [ 3.2301, -1.5471, -2.4218],\n",
       "        [ 2.0925, -0.8687, -1.4452],\n",
       "        [ 3.3891, -1.4428, -2.5200],\n",
       "        [ 0.7687, -0.5063, -0.0777],\n",
       "        [ 0.3220,  0.7492, -0.9896],\n",
       "        [-2.7326,  4.7505, -1.8147],\n",
       "        [-3.0371,  0.0915,  3.5545],\n",
       "        [-3.0599,  5.4489, -2.4418],\n",
       "        [-3.3277,  1.4515,  2.5819],\n",
       "        [-2.1893,  4.2984, -1.9709],\n",
       "        [-2.2092,  2.9925, -0.3155],\n",
       "        [ 0.3298,  0.5173, -0.4869],\n",
       "        [ 4.7028, -2.2552, -3.1390],\n",
       "        [ 3.1888, -1.7502, -1.9018],\n",
       "        [ 5.8135, -3.0478, -3.4969],\n",
       "        [ 4.0387, -2.4649, -2.2277],\n",
       "        [ 2.5562, -1.2066, -1.8117],\n",
       "        [ 1.3242,  0.7908, -2.3088],\n",
       "        [ 2.2455, -1.1931, -1.2654],\n",
       "        [ 0.9174,  0.1085, -0.8659],\n",
       "        [-0.5280,  1.0330, -0.2894],\n",
       "        [-3.4093,  4.3689, -0.6155],\n",
       "        [-2.5243,  3.6800, -0.8662],\n",
       "        [-2.9700,  3.3666,  0.0413],\n",
       "        [-1.1309,  0.7850,  0.9266],\n",
       "        [ 1.2315, -0.0920, -0.8514],\n",
       "        [ 4.0881, -0.0769, -4.7461],\n",
       "        [ 2.7953, -0.3142, -2.7622],\n",
       "        [ 4.9802, -2.0736, -3.7661],\n",
       "        [ 5.4590, -3.0008, -3.2411],\n",
       "        [ 6.6252, -3.7882, -3.4563],\n",
       "        [ 4.1989, -2.3327, -2.5889],\n",
       "        [ 4.4015, -1.9937, -3.1062],\n",
       "        [ 4.4792, -2.3862, -2.7693],\n",
       "        [ 5.1104, -2.4646, -3.4441],\n",
       "        [ 3.7595, -1.7133, -2.4949],\n",
       "        [-1.5594, -0.5617,  2.6415],\n",
       "        [ 2.7752, -0.8208, -2.2464],\n",
       "        [-1.2689,  2.1324, -0.4108],\n",
       "        [ 4.0656, -1.8627, -2.6863],\n",
       "        [ 3.9447, -1.4488, -2.9403],\n",
       "        [ 6.5001, -2.7390, -4.5676],\n",
       "        [ 5.6360, -2.4582, -3.9434],\n",
       "        [ 4.7176, -1.9039, -3.7012],\n",
       "        [ 5.2758, -2.8383, -3.1599],\n",
       "        [ 6.1138, -3.5726, -3.2801],\n",
       "        [ 3.5207, -2.3766, -1.6994],\n",
       "        [ 3.6006, -1.5434, -2.7097],\n",
       "        [ 3.6154, -2.1340, -1.9980],\n",
       "        [ 6.1268, -2.8330, -4.1056],\n",
       "        [ 5.1485, -3.0955, -2.5284],\n",
       "        [ 5.7519, -3.4587, -2.9781],\n",
       "        [-1.2948,  3.3767, -2.0840],\n",
       "        [-2.0155,  0.8279,  1.6365],\n",
       "        [-1.9598,  4.1448, -2.2637],\n",
       "        [ 4.4200, -1.9940, -2.8404],\n",
       "        [ 5.9536, -2.4491, -4.2351],\n",
       "        [ 5.6300, -2.6349, -3.5946],\n",
       "        [ 5.5320, -2.9123, -3.2077],\n",
       "        [ 6.5899, -2.9329, -4.4563],\n",
       "        [ 4.3157, -2.1923, -2.7031],\n",
       "        [ 5.1805, -2.6153, -3.3497],\n",
       "        [ 3.6625, -1.2233, -3.0598],\n",
       "        [ 3.7962, -1.5550, -2.8396],\n",
       "        [ 5.0305, -2.7061, -2.9749],\n",
       "        [ 6.5997, -3.2159, -4.1645],\n",
       "        [ 5.3854, -3.0227, -2.8943],\n",
       "        [ 5.8818, -3.1244, -3.4304],\n",
       "        [-0.5085,  1.1723, -0.2848],\n",
       "        [ 3.3633, -2.2466, -1.3646],\n",
       "        [ 2.7099, -1.0102, -1.8872],\n",
       "        [ 6.0286, -2.8810, -3.7834],\n",
       "        [ 5.2738, -1.8540, -4.1660]], grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_logits = model(input_ids = batch_data[0],\n",
    "                    attention_mask = batch_data[2],\n",
    "                    token_type_ids = batch_data[1])\n",
    "batch_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if batch_logits.ndim < 3:\n",
    "    batch_logits = torch.unsqueeze(batch_logits, 0) # add batch_size dim\n",
    "batch_logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class loss_fn(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(loss_fn, self).__init__()\n",
    "        self.ce_loss = torch.nn.CrossEntropyLoss(ignore_index=-100, reduction = 'mean')\n",
    "\n",
    "    def forward(self, logits, targets, q):\n",
    "  \n",
    "        logits = torch.flatten(logits, start_dim= 0, end_dim = 1)\n",
    "        targets = torch.flatten(targets, start_dim= 0, end_dim = 1)\n",
    "\n",
    "        if q == 0:\n",
    "            loss = self.ce_loss(logits, targets)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "loss_fn = loss_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.1853e-05, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_loss = loss_fn(batch_logits, batch_gt, 0)\n",
    "batch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, betas=(0.9, 0.99), weight_decay=5e-5)\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\"clw8998/Product-Name-NER-model\")\n",
    "evaluate_data = [\n",
    "        {\n",
    "            'context': '【享夢城堡】超柔暖暖毯被150x195cm-角落小夥伴 壽司貓-膚橘',\n",
    "            'question': '品牌',\n",
    "            'answer': [\n",
    "                'O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', \n",
    "                'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', \n",
    "                'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'\n",
    "            ]\n",
    "        }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'input_ids': [[101, 523, 775, 1918, 1814, 1836, 524, 6631, 3382, 3265, 3265, 3691, 6158, 8269, 8206, 8818, 8157, 8341, 118, 6235, 5862, 2207, 1919, 845, 1904, 1385, 6506, 118, 5604, 3580, 102, 1501, 4277, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'offset_mapping': [[(0, 0), (0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 9), (9, 10), (10, 11), (11, 12), (12, 15), (15, 16), (16, 18), (18, 19), (19, 21), (21, 22), (22, 23), (23, 24), (24, 25), (25, 26), (26, 27), (28, 29), (29, 30), (30, 31), (31, 32), (32, 33), (33, 34), (0, 0), (0, 1), (1, 2), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0)]], 'gt': [0, 0, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100], 'p_name': '【享夢城堡】超柔暖暖毯被150x195cm-角落小夥伴 壽司貓-膚橘'}, 0)\n"
     ]
    }
   ],
   "source": [
    "# tokeniz輸入字串，然後改成格式: [BOS] 商品名稱 [SEP] 屬性 [SEP]\n",
    "evaluate_dataset = dataset.BERTDataset_preprocess(evaluate_data, [], tokenizer)\n",
    "print(evaluate_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_loader = DataLoader(dataset = evaluate_dataset,\n",
    "                            batch_size = 1,\n",
    "                            shuffle = False,\n",
    "                            num_workers = 2,\n",
    "                            collate_fn = dataset.BERTDataset_preprocess.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs:\n",
      " tensor([[ 101,  523,  775, 1918, 1814, 1836,  524, 6631, 3382, 3265, 3265, 3691,\n",
      "         6158, 8269, 8206, 8818, 8157, 8341,  118, 6235, 5862, 2207, 1919,  845,\n",
      "         1904, 1385, 6506,  118, 5604, 3580,  102, 1501, 4277,  102,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0]])\n",
      "Attention Mask:\n",
      " tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "Token Type IDs:\n",
      " tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "Index:\n",
      " [0]\n",
      "Batch GT (Ground Truths):\n",
      " tensor([[   0,    0,    2,    1,    1,    1,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100]])\n",
      "Offset Mapping:\n",
      " [[(0, 0), (0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 9), (9, 10), (10, 11), (11, 12), (12, 15), (15, 16), (16, 18), (18, 19), (19, 21), (21, 22), (22, 23), (23, 24), (24, 25), (25, 26), (26, 27), (28, 29), (29, 30), (30, 31), (31, 32), (32, 33), (33, 34), (0, 0), (0, 1), (1, 2), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0)]]\n",
      "P Names:\n",
      " ['【享夢城堡】超柔暖暖毯被150x195cm-角落小夥伴 壽司貓-膚橘']\n"
     ]
    }
   ],
   "source": [
    "for batch_data, index, batch_gt, offset_mapping, p_names in evaluate_loader:\n",
    "    # 提取所需的資料\n",
    "    input_ids = batch_data[0]\n",
    "    attention_mask = batch_data[2]\n",
    "    token_type_ids = batch_data[1]\n",
    "    index = index\n",
    "    batch_gt = batch_gt\n",
    "    offset_mapping = offset_mapping\n",
    "    p_names = p_names\n",
    "\n",
    "    print(\"Input IDs:\\n\", input_ids) # 輸入到模型的資料，token ids\n",
    "    print(\"Attention Mask:\\n\", attention_mask) # 輸入到模型的資料，atteention，0 代表該token不被關注\n",
    "    print(\"Token Type IDs:\\n\", token_type_ids) # 輸入到模型的資料，token type，0 代標商品名稱的token，1 代標問題的token\n",
    "    print(\"Index:\\n\", index) # 用不到\n",
    "    print(\"Batch GT (Ground Truths):\\n\", batch_gt) # 正確答案，2代表實體的B，1代表實體的I，0代表O，-100代表忽略\n",
    "    print(\"Offset Mapping:\\n\", offset_mapping) # 每個token對應到輸入字串的區間\n",
    "    print(\"P Names:\\n\", p_names) # 原始輸入之商品名稱\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 1, 2, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 1, 1, 1, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 1, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_logits = model(input_ids = batch_data[0].to(config.device),\n",
    "                                attention_mask = batch_data[2].to(config.device),\n",
    "                                token_type_ids = batch_data[1].to(config.device))\n",
    "            \n",
    "if batch_logits.ndim < 3:\n",
    "    batch_logits = batch_logits.unsqueeze(0) # add batch size dim\n",
    "\n",
    "batch_pre = torch.argmax(batch_logits, dim = -1) # 取得模型預測的BIO標籤\n",
    "batch_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將模型輸出轉換成 seqeval 模組需要的輸入格式\n",
    "\n",
    "total_gt = {}\n",
    "total_pre = {}\n",
    "\n",
    "for input_ids, token_type_ids, model_pre, gt in zip(batch_data[0], batch_data[1], batch_pre, batch_gt):       \n",
    "    question_start = 0\n",
    "    for id in token_type_ids:\n",
    "        if id == 1:\n",
    "            break\n",
    "        question_start += 1\n",
    "    question = tokenizer.convert_ids_to_tokens(input_ids[question_start : question_start + token_type_ids.sum() - 1])\n",
    "    question = \"\".join(question)\n",
    "\n",
    "    # seqeval\n",
    "    BIO_gt = []\n",
    "    for i in range(1, question_start - 1):\n",
    "        if gt[i] == 2:\n",
    "            BIO_gt.append('B')\n",
    "        elif gt[i] == 1:\n",
    "            BIO_gt.append('I')\n",
    "        elif gt[i] == 0:\n",
    "            BIO_gt.append('O')\n",
    "    \n",
    "    BIO_pre = []\n",
    "    for i in range(1, question_start - 1):\n",
    "        if model_pre[i] == 2:\n",
    "            BIO_pre.append('B')\n",
    "        elif model_pre[i] == 1:\n",
    "            BIO_pre.append('I')\n",
    "        elif model_pre[i] == 0:\n",
    "            BIO_pre.append('O')\n",
    "\n",
    "    if len(BIO_gt) != len(BIO_pre):\n",
    "        pass\n",
    "        print('pred length dont equal gt length ! maybe input too long!')\n",
    "\n",
    "    else:\n",
    "        if question not in total_gt.keys():\n",
    "            total_gt[question] = []\n",
    "        total_gt[question].append(BIO_gt)\n",
    "        if question not in total_pre.keys():\n",
    "            total_pre[question] = []\n",
    "        total_pre[question].append(BIO_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正確答案:\n",
      "{'品牌': [['O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]}\n",
      "模型預測:\n",
      "{'品牌': [['O', 'B', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]}\n"
     ]
    }
   ],
   "source": [
    "print(f\"正確答案:\\n{total_gt}\")\n",
    "print(f\"模型預測:\\n{total_pre}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0000, Recall: 1.0000, F1: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# 使用 seqeval 計算出 precision, recall, f1_score\n",
    "# 將所有屬性的 precision, recall, f1_score 加總取平均，即得到最後的平均 precision, recall, f1_score\n",
    "total_f1 = 0\n",
    "total_p = 0\n",
    "total_r = 0\n",
    "results = []\n",
    "\n",
    "for key in total_gt.keys():\n",
    "    precision = precision_score(total_gt[key], total_pre[key])\n",
    "    recall = recall_score(total_gt[key], total_pre[key])\n",
    "    f1 = f1_score(total_gt[key], total_pre[key])\n",
    "\n",
    "    total_p += precision\n",
    "    total_r += recall\n",
    "    total_f1 += f1\n",
    "    results.append([round(precision,4), round(recall,4), round(f1,4)])\n",
    "    print(f'Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\"clw8998/Product-Name-NER-model\")\n",
    "inference_data = [\n",
    "        {\n",
    "            'context': '【a‵bella浪漫晶飾】方形密碼-深海藍水晶手鍊',\n",
    "            'question': '品牌',\n",
    "            'answer': []\n",
    "        }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'input_ids': [[101, 523, 143, 100, 13192, 3857, 4035, 3253, 7617, 524, 3175, 2501, 2166, 4826, 118, 3918, 3862, 5965, 3717, 3253, 2797, 7101, 102, 1501, 4277, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'offset_mapping': [[(0, 0), (0, 1), (1, 2), (2, 3), (3, 8), (8, 9), (9, 10), (10, 11), (11, 12), (12, 13), (13, 14), (14, 15), (15, 16), (16, 17), (17, 18), (18, 19), (19, 20), (20, 21), (21, 22), (22, 23), (23, 24), (24, 25), (0, 0), (0, 1), (1, 2), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0)]], 'p_name': '【a‵bella浪漫晶飾】方形密碼-深海藍水晶手鍊'}, 0)\n"
     ]
    }
   ],
   "source": [
    "# tokeniz輸入字串，然後改成格式: [BOS] 商品名稱 [SEP] 屬性 [SEP]\n",
    "inference_dataset = dataset.BERTDataset_preprocess(inference_data, [], tokenizer)\n",
    "print(inference_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_loader = DataLoader(dataset = inference_dataset,\n",
    "                            batch_size = 1,\n",
    "                            shuffle = False,\n",
    "                            num_workers = 2,\n",
    "                            collate_fn = dataset.BERTDataset_preprocess.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs:\n",
      " tensor([[  101,   523,   143,   100, 13192,  3857,  4035,  3253,  7617,   524,\n",
      "          3175,  2501,  2166,  4826,   118,  3918,  3862,  5965,  3717,  3253,\n",
      "          2797,  7101,   102,  1501,  4277,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]])\n",
      "Attention Mask:\n",
      " tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "Token Type IDs:\n",
      " tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "Index:\n",
      " [0]\n",
      "Batch GT (Ground Truths):\n",
      " tensor([], dtype=torch.int64)\n",
      "Offset Mapping:\n",
      " [[(0, 0), (0, 1), (1, 2), (2, 3), (3, 8), (8, 9), (9, 10), (10, 11), (11, 12), (12, 13), (13, 14), (14, 15), (15, 16), (16, 17), (17, 18), (18, 19), (19, 20), (20, 21), (21, 22), (22, 23), (23, 24), (24, 25), (0, 0), (0, 1), (1, 2), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0)]]\n",
      "P Names:\n",
      " ['【a‵bella浪漫晶飾】方形密碼-深海藍水晶手鍊']\n"
     ]
    }
   ],
   "source": [
    "for batch_data, index, batch_gt, offset_mapping, p_names in inference_loader:\n",
    "    # 提取所需的資料\n",
    "    input_ids = batch_data[0]\n",
    "    attention_mask = batch_data[2]\n",
    "    token_type_ids = batch_data[1]\n",
    "    index = index\n",
    "    batch_gt = batch_gt\n",
    "    offset_mapping = offset_mapping\n",
    "    p_names = p_names\n",
    "\n",
    "    print(\"Input IDs:\\n\", input_ids) # 輸入到模型的資料，token ids\n",
    "    print(\"Attention Mask:\\n\", attention_mask) # 輸入到模型的資料，atteention，0 代表該token不被關注\n",
    "    print(\"Token Type IDs:\\n\", token_type_ids) # 輸入到模型的資料，token type，0 代標商品名稱的token，1 代標問題的token\n",
    "    print(\"Index:\\n\", index) # 用不到\n",
    "    print(\"Batch GT (Ground Truths):\\n\", batch_gt) # 正確答案，2代表實體的B，1代表實體的I，0代表O，-100代表忽略\n",
    "    print(\"Offset Mapping:\\n\", offset_mapping) # 每個token對應到輸入字串的區間\n",
    "    print(\"P Names:\\n\", p_names) # 原始輸入之商品名稱\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 2, 1, 1, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "         0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_logits = model(input_ids = batch_data[0].to(config.device),\n",
    "                                attention_mask = batch_data[2].to(config.device),\n",
    "                                token_type_ids = batch_data[1].to(config.device))\n",
    "            \n",
    "if batch_logits.ndim < 3:\n",
    "    batch_logits = batch_logits.unsqueeze(0) # add batch size dim\n",
    "\n",
    "batch_pre = torch.argmax(batch_logits, dim = -1) # 取得模型預測的BIO標籤\n",
    "batch_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_text = []\n",
    "result_pos = []\n",
    "result_confidence = []\n",
    "\n",
    "# 對 batch 中的每個樣本進行處理\n",
    "for input_ids, token_type_ids, model_pre, offset, logits, p_name in zip(batch_data[0], batch_data[1], batch_pre, offset_mapping, batch_logits, p_names):\n",
    "\n",
    "    # 取出問題(屬性)\n",
    "    question_start = int(token_type_ids.argmax(-1)) # 找到問題的開始位置\n",
    "    question = tokenizer.convert_ids_to_tokens(input_ids[question_start : question_start + token_type_ids.sum() - 1]) # 根據 token_type_ids 提取問題\n",
    "    question = \"\".join(question) # 將 token 轉換為字符串\n",
    "\n",
    "    # 取出商品名稱\n",
    "    offset = offset[1:question_start - 1] # 移除CLS和問題的offset\n",
    "    # 產生一個存放 token 的 list\n",
    "    context = [' '] * (offset[-1][1]) # 根據最後一個token的index產生一個空白字符的列表\n",
    "    for idx, text in enumerate(tokenizer.convert_ids_to_tokens(input_ids[1:question_start - 1])):\n",
    "        if text == '[UNK]': # 如果是 UNK token 就從商品名稱中取值\n",
    "            context[offset[idx][0] : offset[idx][1]] = list(p_name[offset[idx][0] : offset[idx][1]])\n",
    "        else:\n",
    "            context[offset[idx][0] : offset[idx][1]] = list(text.replace('##', '')) # '##'代表與前一個 token 相連\n",
    "    context = \"\".join(context) # 將 context 轉換為字符串\n",
    "\n",
    "    # 初始化結果列表\n",
    "    result_text.append([context, {}])\n",
    "    result_pos.append([context, {}])\n",
    "    result_confidence.append([context, {}])\n",
    "\n",
    "    # 取得每個字元的 confidence\n",
    "    tmp_confidence = []\n",
    "    last_idx = 0\n",
    "    # 計算 softmax，並取出最大值作為 confidence\n",
    "    for idx, confidence in enumerate(torch.nn.functional.softmax(logits[1:question_start - 1], dim=-1).max(-1)[0].detach().cpu().numpy().tolist()):\n",
    "        # 若一個token超過一個字元，只有最後一個字元會被賦予 confifence，其餘都是 0.0\n",
    "        # ex: \"bella\" 是單一一個 token 且信心值為 0.9，則 \"bella\" 每個字元信心值為: [0.0, 0.0, 0.0, 0.0, 0.9]\n",
    "        # 計算時，會忽略補充的\n",
    "        if last_idx < offset[idx][0]:\n",
    "            tmp_confidence += [0.0] * (offset[idx][0] - last_idx) # 填充 0.0 表示非 token 的部分\n",
    "        tmp_confidence = tmp_confidence + ([0.0] * (offset[idx][1] - offset[idx][0] - 1)) + [confidence]\n",
    "        last_idx = offset[idx][1]\n",
    "    \n",
    "    # 將 confidence 加入結果\n",
    "    result_confidence[-1][1][question] = tmp_confidence\n",
    "\n",
    "    model_pre = model_pre[1:] # 移除CLS token的預測結果\n",
    "\n",
    "    # 取得實體與區間\n",
    "    i = 0\n",
    "    start = 0\n",
    "    attribute_values = []\n",
    "    attribute_positions = []\n",
    "    while i <= question_start - 2:\n",
    "        if model_pre[i] == 2: # 遇到標記 2 表示一個屬性的開始\n",
    "            if i > start:\n",
    "                attribute_values.append(context[offset[start][0]:offset[i - 1][1]]) # 添加屬性的值\n",
    "                attribute_positions.append([offset[start][0], offset[i - 1][1] - 1]) # 添加屬性的位置\n",
    "                start = i\n",
    "            elif i == start:\n",
    "                pass\n",
    "            i += 1\n",
    "        elif model_pre[i] == 1: # 遇到標記 1 表示屬性中間\n",
    "            i += 1\n",
    "            if i == start:\n",
    "                start = i\n",
    "        elif model_pre[i] == 0: # 遇到標記 0 表示屬性結束\n",
    "            if i > start:\n",
    "                attribute_values.append(context[offset[start][0]:offset[i - 1][1]]) # 添加屬性的值\n",
    "                attribute_positions.append([offset[start][0], offset[i - 1][1] - 1]) # 添加屬性的位置\n",
    "            i += 1\n",
    "            start = i\n",
    "    \n",
    "    # 將實體與區間結果\n",
    "    result_text[-1][1][question] = attribute_values\n",
    "    result_pos[-1][1][question] = attribute_positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['【a‵bella浪漫晶飾】方形密碼-深海藍水晶手鍊', {'品牌': ['a‵bella', '浪漫晶飾']}]],\n",
       " [['【a‵bella浪漫晶飾】方形密碼-深海藍水晶手鍊', {'品牌': [[1, 7], [8, 11]]}]],\n",
       " [['【a‵bella浪漫晶飾】方形密碼-深海藍水晶手鍊',\n",
       "   {'品牌': [0.9999871253967285,\n",
       "     0.9990952014923096,\n",
       "     0.9973575472831726,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.9998403787612915,\n",
       "     0.9588338136672974,\n",
       "     0.9993359446525574,\n",
       "     0.9996674060821533,\n",
       "     0.9995212554931641,\n",
       "     0.9999836683273315,\n",
       "     0.9999616146087646,\n",
       "     0.9999741315841675,\n",
       "     0.9998793601989746,\n",
       "     0.9999148845672607,\n",
       "     0.9999858140945435,\n",
       "     0.999988317489624,\n",
       "     0.9999903440475464,\n",
       "     0.9999902248382568,\n",
       "     0.9999865293502808,\n",
       "     0.9999830722808838,\n",
       "     0.999980092048645,\n",
       "     0.999985933303833]}]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_text, result_pos, result_confidence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
